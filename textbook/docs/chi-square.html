<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>9 Chi Square | Reproducible statistics for psychologists with R</title>
<meta name="author" content="Matthew J. C. Crump">
<!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.2"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/header-attrs-2.5.3/header-attrs.js"></script><script src="libs/jquery-3.5.1/jquery-3.5.1.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap-4.5.3/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap-4.5.3/bootstrap.bundle.min.js"></script><script src="libs/bs3compat-0.2.3.9000/tabs.js"></script><script src="libs/bs3compat-0.2.3.9000/bs3compat.js"></script><link href="libs/bs_font_google_work%20sans-0.2.3.9000/font.css" rel="stylesheet">
<link href="libs/bs_font_google_major%20mono%20display-0.2.3.9000/font.css" rel="stylesheet">
<link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet">
<script src="libs/bs4_book-1.0.0/bs4_book.js"></script><script src="libs/kePrint-0.0.1/kePrint.js"></script><link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet">
<!-- Global site tag (gtag.js) - Google Analytics --><script async src="https://www.googletagmanager.com/gtag/js?id=G-TJYWEN5QYP"></script><script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-TJYWEN5QYP');
    </script><link rel="icon" href="https://crumplab.github.io/rstatsforpsych/favicon.ico">
<meta property="og:card" content="website">
<meta property="og:title" content="9 Chi Square | Reproducible statistics for psychologists with R">
<meta property="og:image" content="https://crumplab.github.io/rstatsforpsych/imgs/cover.png">
<meta property="og:url" content="https://crumplab.github.io/rstatsforpsych/">
<meta property="og:description" content="A lab curriculum for psych stats that introduces R and scripting for reproducible analyses.">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:site" content="@MattCrump_">
<meta name="twitter:title" content="9 Chi Square | Reproducible statistics for psychologists with R">
<meta name="twitter:description" content="A lab curriculum for psych stats that introduces R and scripting for reproducible analyses.">
<meta name="twitter:image" content="https://crumplab.github.io/rstatsforpsych/imgs/rstats_large.png">
<script src="https://cdn.jsdelivr.net/autocomplete.js/0/autocomplete.jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/mark.js@8.11.1/dist/mark.min.js"></script><!-- CSS --><link rel="stylesheet" href="custom.css">
</head>
<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="Lab Tutorials">Reproducible statistics for psychologists with R</a>:
        <small class="text-muted">Lab Tutorials</small>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Search" aria-label="Search">
</form>

      <nav aria-label="Table of contents"><h2>Table of contents</h2>
        <ul class="book-toc list-unstyled">
<li><a class="" href="index.html">Welcome</a></li>
<li><a class="" href="preface.html">Preface</a></li>
<li class="book-part">Getting started</li>
<li><a class="" href="r-rstudio-github.html">R, RStudio, &amp; Github</a></li>
<li><a class="" href="basic-r-programming.html">Basic R programming</a></li>
<li><a class="" href="practice-problems.html">Practice problems</a></li>
<li><a class="" href="coding-reference.html">Coding Reference</a></li>
<li><a class="" href="textbooks-and-other-resources.html">Textbooks and Other Resources</a></li>
<li class="book-part">Labs</li>
<li><a class="" href="r-basics.html"><span class="header-section-number">1</span> R Basics</a></li>
<li><a class="" href="descriptives.html"><span class="header-section-number">2</span> Descriptives</a></li>
<li><a class="" href="distributions-i.html"><span class="header-section-number">3</span> Distributions I</a></li>
<li><a class="" href="distributions-ii.html"><span class="header-section-number">4</span> Distributions II</a></li>
<li><a class="" href="sampling-distributions.html"><span class="header-section-number">5</span> Sampling Distributions</a></li>
<li><a class="" href="statistical-inference.html"><span class="header-section-number">6</span> Statistical Inference</a></li>
<li><a class="" href="binomial-test.html"><span class="header-section-number">7</span> Binomial Test</a></li>
<li><a class="" href="z-tests.html"><span class="header-section-number">8</span> Z tests</a></li>
<li><a class="active" href="chi-square.html"><span class="header-section-number">9</span> Chi Square</a></li>
<li><a class="" href="t-tests.html"><span class="header-section-number">10</span> T-tests</a></li>
<li><a class="" href="simulation-and-power-analysis.html">Simulation and Power Analysis</a></li>
<li><a class="" href="correlation.html"><span class="header-section-number">11</span> Correlation</a></li>
<li><a class="" href="regression.html"><span class="header-section-number">12</span> Regression</a></li>
<li><a class="" href="semester-1-project.html">Semester 1 project</a></li>
<li><a class="" href="references-1.html">References</a></li>
</ul>

        <div class="book-extra">
          <p><a id="book-repo" href="https://github.com/CrumpLab/rstatsforpsych">View book source <i class="fab fa-github"></i></a></p>
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><div id="chi-square" class="section level1" number="9">
<h1>
<span class="header-section-number">9</span> Chi Square<a class="anchor" aria-label="anchor" href="#chi-square"><i class="fas fa-link"></i></a>
</h1>
<p>“10/8/2020 | Last Compiled: 2020-12-14”</p>
<div id="reading-4" class="section level2" number="9.1">
<h2>
<span class="header-section-number">9.1</span> Reading<a class="anchor" aria-label="anchor" href="#reading-4"><i class="fas fa-link"></i></a>
</h2>
<p><span class="citation"><a href="references-1.html#ref-vokeyThinkingData7th2018" role="doc-biblioref">Vokey &amp; Allen</a>,<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content='&lt;p&gt;&lt;a href="references-1.html#ref-vokeyThinkingData7th2018" role="doc-biblioref"&gt;2018&lt;/a&gt;.&lt;/p&gt;'><sup>29</sup></a></span> Chapter 13.</p>
</div>
<div id="overview-8" class="section level2" number="9.2">
<h2>
<span class="header-section-number">9.2</span> Overview<a class="anchor" aria-label="anchor" href="#overview-8"><i class="fas fa-link"></i></a>
</h2>
<p>This lab provides a conceptual foundation for understanding the chi square test using R.</p>
<div class="videoWrapper">
<iframe width="560" height="315" src="https://www.youtube.com/embed/gJ5qR_ebDvk" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
</div>
</div>
<div id="background" class="section level2" number="9.3">
<h2>
<span class="header-section-number">9.3</span> Background<a class="anchor" aria-label="anchor" href="#background"><i class="fas fa-link"></i></a>
</h2>
<div id="a-brief-history" class="section level3" number="9.3.1">
<h3>
<span class="header-section-number">9.3.1</span> A brief history<a class="anchor" aria-label="anchor" href="#a-brief-history"><i class="fas fa-link"></i></a>
</h3>
<p>Karl Pearson described the chi-square test in 1900.<span class="citation"><a class="footnote-ref" tabindex="0" data-toggle="popover" data-content='&lt;p&gt;&lt;a href="references-1.html#ref-pearsonCriterionThatGiven1900" role="doc-biblioref"&gt;Pearson, Karl. (1900). X. &lt;span&gt;On&lt;/span&gt; the criterion that a given system of deviations from the probable in the case of a correlated system of variables is such that it can be reasonably supposed to have arisen from random sampling. &lt;em&gt;The London, Edinburgh, and Dublin Philosophical Magazine and Journal of Science&lt;/em&gt;, &lt;em&gt;50&lt;/em&gt;(302), 157–175. &lt;/a&gt;&lt;a href="https://doi.org/cpxzh4" role="doc-biblioref"&gt;https://doi.org/cpxzh4&lt;/a&gt;.&lt;/p&gt;'><sup>30</sup></a></span> Also see <span class="citation"><a href="references-1.html#ref-plackettKarlPearsonChiSquared1983" role="doc-biblioref">Plackett, R. L.</a><a class="footnote-ref" tabindex="0" data-toggle="popover" data-content='&lt;p&gt;&lt;a href="references-1.html#ref-plackettKarlPearsonChiSquared1983" role="doc-biblioref"&gt;(1983). Karl &lt;span&gt;Pearson&lt;/span&gt; and the &lt;span&gt;Chi&lt;/span&gt;-&lt;span&gt;Squared Test&lt;/span&gt;. &lt;em&gt;International Statistical Review / Revue Internationale de Statistique&lt;/em&gt;, &lt;em&gt;51&lt;/em&gt;(1), 59. &lt;/a&gt;&lt;a href="https://doi.org/d55k57" role="doc-biblioref"&gt;https://doi.org/d55k57&lt;/a&gt;.&lt;/p&gt;'><sup>31</sup></a></span> for additional context about the development of this test. Relatedly, Pearson had an undeniably large impact on the discipline of statistics; although a socio-historical account is beyond the scope of this lab, it is worth pointing out that Pearson (like many of his contemporaries) was heavily involved in the eugenics movement,<span class="citation"><a class="footnote-ref" tabindex="0" data-toggle="popover" data-content='&lt;p&gt;&lt;a href="references-1.html#ref-semmelKarlPearsonSocialist1958" role="doc-biblioref"&gt;Semmel, B. (1958). Karl &lt;span&gt;Pearson&lt;/span&gt;: &lt;span&gt;Socialist&lt;/span&gt; and &lt;span&gt;Darwinist&lt;/span&gt;. &lt;em&gt;The British Journal of Sociology&lt;/em&gt;, &lt;em&gt;9&lt;/em&gt;(2), 111. &lt;/a&gt;&lt;a href="https://doi.org/fs4jbb" role="doc-biblioref"&gt;https://doi.org/fs4jbb&lt;/a&gt;.&lt;/p&gt;'><sup>32</sup></a></span> and he not only developed statistical techniques, but also applied them to those causes (interested readers could see examples in Pearson’s publications in eugenics journals).</p>
</div>
<div id="chi-square-distributions-have-fundamental-properties-that-make-them-widespread-in-statistics" class="section level3" number="9.3.2">
<h3>
<span class="header-section-number">9.3.2</span> Chi-square distributions have fundamental properties that make them widespread in statistics<a class="anchor" aria-label="anchor" href="#chi-square-distributions-have-fundamental-properties-that-make-them-widespread-in-statistics"><i class="fas fa-link"></i></a>
</h3>
<p>The chi-square (<span class="math inline">\(\chi^2\)</span>) test, statistic, and associated distribution are fundamental to many other aspects of statistics. A full accounting of the many connections and mathematical relationships is beyond the scope of this lab (but see wikipedia articles on the <a href="https://en.wikipedia.org/wiki/Chi-squared_test">chi-square test</a>, and <a href="https://en.wikipedia.org/wiki/Chi-square_distribution">chi-square distribution</a> ).</p>
</div>
<div id="debate-about-correct-usage" class="section level3" number="9.3.3">
<h3>
<span class="header-section-number">9.3.3</span> Debate about correct usage<a class="anchor" aria-label="anchor" href="#debate-about-correct-usage"><i class="fas fa-link"></i></a>
</h3>
<p>The chi-square test has multiple uses in psychology, including tests of independence and goodness of fit. The “correct” usage of chi-square tests is not without debate. For example, roughly 50 years after Pearson, <span class="citation"><a href="references-1.html#ref-lewisUseMisuseChisquare1949" role="doc-biblioref">Lewis, D., &amp; Burke, C. J.</a><a class="footnote-ref" tabindex="0" data-toggle="popover" data-content='&lt;p&gt;&lt;a href="references-1.html#ref-lewisUseMisuseChisquare1949" role="doc-biblioref"&gt;(1949). The use and misuse of the chi-square test. &lt;em&gt;Psychological Bulletin&lt;/em&gt;, &lt;em&gt;46&lt;/em&gt;(6), 433. &lt;/a&gt;&lt;a href="https://doi.org/frkdqw" role="doc-biblioref"&gt;https://doi.org/frkdqw&lt;/a&gt;.&lt;/p&gt;'><sup>33</sup></a></span> wrote a lengthy paper describing “uses and misuses” of chi-square tests in psychology. There were several replies by other authors who were identified as “misusing” the chi-square test. More recently, the suggestions of <span class="citation"><a href="references-1.html#ref-lewisUseMisuseChisquare1949" role="doc-biblioref">Lewis &amp; Burke</a><a class="footnote-ref" tabindex="0" data-toggle="popover" data-content='&lt;p&gt;&lt;a href="references-1.html#ref-lewisUseMisuseChisquare1949" role="doc-biblioref"&gt;1949&lt;/a&gt;.&lt;/p&gt;'><sup>34</sup></a></span> were revisited by <span class="citation"><a href="references-1.html#ref-delucchiUseMisuseChisquare1983" role="doc-biblioref">Delucchi, K. L.</a><a class="footnote-ref" tabindex="0" data-toggle="popover" data-content='&lt;p&gt;&lt;a href="references-1.html#ref-delucchiUseMisuseChisquare1983" role="doc-biblioref"&gt;(1983). The use and misuse of chi-square: &lt;span&gt;Lewis&lt;/span&gt; and &lt;span&gt;Burke&lt;/span&gt; revisited. &lt;em&gt;Psychological Bulletin&lt;/em&gt;, &lt;em&gt;94&lt;/em&gt;(1), 166&lt;/a&gt;.&lt;/p&gt;'><sup>35</sup></a></span> These papers scratch the surface of the many uses and misuses of chi-square tests in psychology. An ongoing goal in our labs is to develop your conceptual understanding of the statistics you use so that you can justify why your usage is appropriate to your analysis.</p>
</div>
<div id="connection-to-previous-lab-concepts" class="section level3" number="9.3.4">
<h3>
<span class="header-section-number">9.3.4</span> Connection to previous lab concepts<a class="anchor" aria-label="anchor" href="#connection-to-previous-lab-concepts"><i class="fas fa-link"></i></a>
</h3>
<p>In previous labs we have conducted statistical inference by adopting similar general procedures. We obtain sample data. We consider how the sample could have arisen by random sampling, and construct a sampling distribution. Then we compare our sample data to the sampling distribution to see if it was likely or unlikely to have been produced by chance. Sometimes we have simulated the sampling distribution, and other times we have used formulas to compute precise probabilities.</p>
<p>The chi-square test is another specific example of the general procedure described above. We can obtain sample data, compute a <span class="math inline">\(\chi^2\)</span> statistic for the sample data, and then compare that statistic to a reference null distribution to determine the probability of obtaining that value by chance.</p>
</div>
</div>
<div id="practical-i-chisq.test-in-r" class="section level2" number="9.4">
<h2>
<span class="header-section-number">9.4</span> Practical I: <code>chisq.test()</code> in R<a class="anchor" aria-label="anchor" href="#practical-i-chisq.test-in-r"><i class="fas fa-link"></i></a>
</h2>
<p>Base R comes with several functions for chi-square tests, including <code><a href="https://rdrr.io/r/stats/chisq.test.html">chisq.test()</a></code> and the family of <span class="math inline">\(\chi^2\)</span> distribution functions: <code>dchisqu()</code>, <code>pchisqu()</code>, <code>qchisqu()</code>, and <code>rchisqu()</code>.</p>
<div id="chisq.test" class="section level3" number="9.4.1">
<h3>
<span class="header-section-number">9.4.1</span> chisq.test()<a class="anchor" aria-label="anchor" href="#chisq.test"><i class="fas fa-link"></i></a>
</h3>
<p>The <code><a href="https://rdrr.io/r/stats/chisq.test.html">chisq.test()</a></code> function performs basic tests of independence for vectors and contingency tables.</p>
<div class="sourceCode" id="cb319"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="op">?</span><span class="va">chisq.test</span></code></pre></div>
<div id="test-for-a-frequency-vector" class="section level4" number="9.4.1.1">
<h4>
<span class="header-section-number">9.4.1.1</span> Test for a frequency vector<a class="anchor" aria-label="anchor" href="#test-for-a-frequency-vector"><i class="fas fa-link"></i></a>
</h4>
<p>Inputting a single vector of values conducts a chi-square test with N-1 degrees of freedom. The test assumes equal probability of outcome by default, and reports the chi-square sample statistic, as a well as the p-value associated with a <span class="math inline">\(\chi^2\)</span> distribution with N-1 degrees of freedom.</p>
<p>Toss a coin 50 times and receive 20 heads and 30 tails. Conduct a chi-square test of independence, and assume the theoretically expected frequencies are 25 and 25.</p>
<div class="sourceCode" id="cb320"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">my_vals</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">20</span>,<span class="fl">30</span><span class="op">)</span>
<span class="op">(</span><span class="va">xsq</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/chisq.test.html">chisq.test</a></span><span class="op">(</span><span class="va">my_vals</span><span class="op">)</span><span class="op">)</span>
<span class="co">#&gt; </span>
<span class="co">#&gt;  Chi-squared test for given probabilities</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; data:  my_vals</span>
<span class="co">#&gt; X-squared = 2, df = 1, p-value = 0.1573</span>

<span class="va">xsq</span><span class="op">$</span><span class="va">statistic</span>
<span class="co">#&gt; X-squared </span>
<span class="co">#&gt;         2</span>
<span class="va">xsq</span><span class="op">$</span><span class="va">observed</span>
<span class="co">#&gt; [1] 20 30</span>
<span class="va">xsq</span><span class="op">$</span><span class="va">expected</span>
<span class="co">#&gt; [1] 25 25</span>
<span class="va">xsq</span><span class="op">$</span><span class="va">residuals</span>
<span class="co">#&gt; [1] -1  1</span>


<span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="op">(</span><span class="op">(</span><span class="va">xsq</span><span class="op">$</span><span class="va">observed</span> <span class="op">-</span> <span class="va">xsq</span><span class="op">$</span><span class="va">expected</span><span class="op">)</span><span class="op">^</span><span class="fl">2</span><span class="op">)</span> <span class="op">/</span> <span class="va">xsq</span><span class="op">$</span><span class="va">expected</span><span class="op">)</span>
<span class="co">#&gt; [1] 2</span></code></pre></div>
<p>It is possible to specify different theoretical probabilities:</p>
<div class="sourceCode" id="cb321"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">my_vals</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">20</span>,<span class="fl">30</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/stats/chisq.test.html">chisq.test</a></span><span class="op">(</span><span class="va">my_vals</span>, p <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">.25</span>,<span class="fl">.75</span><span class="op">)</span><span class="op">)</span>
<span class="co">#&gt; </span>
<span class="co">#&gt;  Chi-squared test for given probabilities</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; data:  my_vals</span>
<span class="co">#&gt; X-squared = 6, df = 1, p-value = 0.01431</span></code></pre></div>
<p>The vector can be any length, e.g., roll a dice 120 times and count the number of times each number from 1 to 6 occurs, then conduct a chi-square test of independence:</p>
<div class="sourceCode" id="cb322"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">my_vals</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">20</span>,<span class="fl">30</span>,<span class="fl">10</span>,<span class="fl">10</span>,<span class="fl">30</span>,<span class="fl">30</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/stats/chisq.test.html">chisq.test</a></span><span class="op">(</span><span class="va">my_vals</span><span class="op">)</span>
<span class="co">#&gt; </span>
<span class="co">#&gt;  Chi-squared test for given probabilities</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; data:  my_vals</span>
<span class="co">#&gt; X-squared = 22.308, df = 5, p-value = 0.0004576</span></code></pre></div>
</div>
</div>
<div id="independence-test-for-a-contingency-table" class="section level3" number="9.4.2">
<h3>
<span class="header-section-number">9.4.2</span> Independence test for a contingency table<a class="anchor" aria-label="anchor" href="#independence-test-for-a-contingency-table"><i class="fas fa-link"></i></a>
</h3>
<p>A matrix describing a contingency table with positive values in rows and columns can also be inputted directly to the function. Here, the null hypothesis is that the “joint distribution of the cell counts in the contingency table is the product of row and column marginals.” The degrees of freedom is defined as <span class="math inline">\((r-1)(c-1)\)</span>, where <span class="math inline">\(r\)</span> is the number of rows and <span class="math inline">\(c\)</span> is the number of columns.</p>
<p>The following example is from the help file:</p>
<div class="sourceCode" id="cb323"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">M</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/table.html">as.table</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/cbind.html">rbind</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">762</span>, <span class="fl">327</span>, <span class="fl">468</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">484</span>, <span class="fl">239</span>, <span class="fl">477</span><span class="op">)</span><span class="op">)</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/base/dimnames.html">dimnames</a></span><span class="op">(</span><span class="va">M</span><span class="op">)</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span>gender <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"F"</span>, <span class="st">"M"</span><span class="op">)</span>,
                    party <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"Democrat"</span>,<span class="st">"Independent"</span>, <span class="st">"Republican"</span><span class="op">)</span><span class="op">)</span>
<span class="op">(</span><span class="va">Xsq</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/chisq.test.html">chisq.test</a></span><span class="op">(</span><span class="va">M</span><span class="op">)</span><span class="op">)</span>  <span class="co"># Prints test summary</span>
<span class="co">#&gt; </span>
<span class="co">#&gt;  Pearson's Chi-squared test</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; data:  M</span>
<span class="co">#&gt; X-squared = 30.07, df = 2, p-value = 2.954e-07</span>
<span class="va">Xsq</span><span class="op">$</span><span class="va">observed</span>   <span class="co"># observed counts (same as M)</span>
<span class="co">#&gt;       party</span>
<span class="co">#&gt; gender Democrat Independent Republican</span>
<span class="co">#&gt;      F      762         327        468</span>
<span class="co">#&gt;      M      484         239        477</span>
<span class="va">Xsq</span><span class="op">$</span><span class="va">expected</span>   <span class="co"># expected counts under the null</span>
<span class="co">#&gt;       party</span>
<span class="co">#&gt; gender Democrat Independent Republican</span>
<span class="co">#&gt;      F 703.6714    319.6453   533.6834</span>
<span class="co">#&gt;      M 542.3286    246.3547   411.3166</span>
<span class="va">Xsq</span><span class="op">$</span><span class="va">residuals</span>  <span class="co"># Pearson residuals</span>
<span class="co">#&gt;       party</span>
<span class="co">#&gt; gender   Democrat Independent Republican</span>
<span class="co">#&gt;      F  2.1988558   0.4113702 -2.8432397</span>
<span class="co">#&gt;      M -2.5046695  -0.4685829  3.2386734</span>
<span class="va">Xsq</span><span class="op">$</span><span class="va">stdres</span>     <span class="co"># standardized residuals</span>
<span class="co">#&gt;       party</span>
<span class="co">#&gt; gender   Democrat Independent Republican</span>
<span class="co">#&gt;      F  4.5020535   0.6994517 -5.3159455</span>
<span class="co">#&gt;      M -4.5020535  -0.6994517  5.3159455</span>
<span class="va">Xsq</span><span class="op">$</span><span class="va">p.value</span>
<span class="co">#&gt; [1] 2.953589e-07</span>
<span class="va">Xsq</span><span class="op">$</span><span class="va">statistic</span>
<span class="co">#&gt; X-squared </span>
<span class="co">#&gt;  30.07015</span></code></pre></div>
</div>
</div>
<div id="conceptual-i-chi2-distribution-sample-statistic-and-test" class="section level2" number="9.5">
<h2>
<span class="header-section-number">9.5</span> Conceptual I: <span class="math inline">\(\chi^2\)</span> distribution, sample statistic, and test<a class="anchor" aria-label="anchor" href="#conceptual-i-chi2-distribution-sample-statistic-and-test"><i class="fas fa-link"></i></a>
</h2>
<p>Chi-square (<span class="math inline">\(\chi^2\)</span>) statistics can be confusing because <span class="math inline">\(\chi^2\)</span> can refer to distributions, a sample statistic, and statistical inference tests.</p>
<p>The <span class="math inline">\(\chi^2\)</span> <strong>distribution</strong> is a family of distributions that arise when you sum the squared values of random samples from a unit normal distribution:</p>
<p><span class="math inline">\(\chi^2 = \sum_{i=1}^k Z_i^2\)</span></p>
<p>Where, <span class="math inline">\(Z_i^2\)</span> is a random deviate from a unit normal distribution (mean = 0, sd =1), and <span class="math inline">\(k\)</span> is the number of random samples (also known as the degrees of freedom, or number of samples free to independently vary). When <span class="math inline">\(k=1\)</span>, the <span class="math inline">\(\chi^2\)</span> distribution is a unit normal distribution squared.</p>
<p>The <span class="math inline">\(\chi^2\)</span> <strong>sample statistic</strong> is a formula that can be applied to frequency data to summarize the amount by which the observed frequencies differ from theoretically expected frequencies.</p>
<p><span class="math inline">\(\chi^2 = \sum{\frac{(\text{Observed} - \text{Expected})^2}{\text{Expected}}}\)</span></p>
<p><span class="math inline">\(\chi^2 = \sum_{i=1}^n{\frac{(\text{O}_i - \text{E}_i)^2}{\text{E}_i}}\)</span></p>
<p><span class="math inline">\(\chi^2\)</span> <strong>statistical tests</strong> (such as a test of independence, or goodness of fit) are used for inference about the role of chance in producing observed frequency data. The process involves computing the <span class="math inline">\(\chi^2\)</span> sample statistic on observed frequency data, then comparing the obtained value to a <span class="math inline">\(\chi^2\)</span> distribution with the same degrees of freedom as the sample. The probability of obtaining the <span class="math inline">\(\chi^2\)</span> sample statistic or larger generally approximates the probability that an independent random sampling process could have produced deviations from the expected frequencies as large as or larger than that found in the sample.</p>
<div id="the-chi2-sample-statistic" class="section level3" number="9.5.1">
<h3>
<span class="header-section-number">9.5.1</span> The <span class="math inline">\(\chi^2\)</span> sample statistic<a class="anchor" aria-label="anchor" href="#the-chi2-sample-statistic"><i class="fas fa-link"></i></a>
</h3>
<p>Below are two ways of writing the formula for the <span class="math inline">\(\chi^2\)</span> sample statistic.</p>
<p><span class="math inline">\(\chi^2 = \sum{\frac{(\text{Observed} - \text{Expected})^2}{\text{Expected}}}\)</span></p>
<p><span class="math inline">\(\chi^2 = \sum_{i=1}^n{\frac{(\text{O}_i - \text{E}_i)^2}{\text{E}_i}}\)</span></p>
<p>The <span class="math inline">\(\chi^2\)</span> sample statistic is used to summarize obtained frequency data, specifically in a way that relates the obtained frequencies to theoretically expected frequencies.</p>
<p>For example, if you tossed a coin 50 times, and found the following observed frequencies of heads and tails, you could compare them to the expected frequencies if the coin was fair.</p>
<div class="sourceCode" id="cb324"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">coin_toss</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span>outcome <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"H"</span>,<span class="st">"T"</span><span class="op">)</span>,
                        O <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">23</span>,<span class="fl">27</span><span class="op">)</span>,
                        E <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">25</span>,<span class="fl">25</span><span class="op">)</span><span class="op">)</span>
<span class="fu">knitr</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/knitr/man/kable.html">kable</a></span><span class="op">(</span><span class="va">coin_toss</span><span class="op">)</span></code></pre></div>
<div class="inline-table"><table class="table table-sm">
<thead><tr class="header">
<th align="left">outcome</th>
<th align="right">O</th>
<th align="right">E</th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="left">H</td>
<td align="right">23</td>
<td align="right">25</td>
</tr>
<tr class="even">
<td align="left">T</td>
<td align="right">27</td>
<td align="right">25</td>
</tr>
</tbody>
</table></div>
<p>Thus, each outcome has an observed value (<span class="math inline">\(O_i\)</span>) and expected value (<span class="math inline">\(E_i\)</span>), and <span class="math inline">\(\chi^2\)</span> can be computed:</p>
<div class="sourceCode" id="cb325"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://dplyr.tidyverse.org">dplyr</a></span><span class="op">)</span>

<span class="va">coin_toss</span> <span class="op">&lt;-</span> <span class="va">coin_toss</span> <span class="op">%&gt;%</span>
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span>d <span class="op">=</span> <span class="va">O</span> <span class="op">-</span> <span class="va">E</span><span class="op">)</span> <span class="op">%&gt;%</span>
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span>d_sq <span class="op">=</span> <span class="va">d</span><span class="op">^</span><span class="fl">2</span><span class="op">)</span> <span class="op">%&gt;%</span>
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span>div <span class="op">=</span> <span class="va">d_sq</span><span class="op">/</span><span class="va">E</span> <span class="op">)</span>

<span class="fu">knitr</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/knitr/man/kable.html">kable</a></span><span class="op">(</span><span class="va">coin_toss</span><span class="op">)</span></code></pre></div>
<div class="inline-table"><table class="table table-sm">
<thead><tr class="header">
<th align="left">outcome</th>
<th align="right">O</th>
<th align="right">E</th>
<th align="right">d</th>
<th align="right">d_sq</th>
<th align="right">div</th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="left">H</td>
<td align="right">23</td>
<td align="right">25</td>
<td align="right">-2</td>
<td align="right">4</td>
<td align="right">0.16</td>
</tr>
<tr class="even">
<td align="left">T</td>
<td align="right">27</td>
<td align="right">25</td>
<td align="right">2</td>
<td align="right">4</td>
<td align="right">0.16</td>
</tr>
</tbody>
</table></div>
<div class="sourceCode" id="cb326"><pre class="downlit sourceCode r">
<code class="sourceCode R">
<span class="co"># compute chi-square</span>
<span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">coin_toss</span><span class="op">$</span><span class="va">div</span><span class="op">)</span>
<span class="co">#&gt; [1] 0.32</span>

<span class="co"># compute chi-square </span>
<span class="va">O</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">23</span>,<span class="fl">27</span><span class="op">)</span>
<span class="va">E</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">25</span>,<span class="fl">25</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="op">(</span><span class="op">(</span><span class="va">O</span><span class="op">-</span><span class="va">E</span><span class="op">)</span><span class="op">^</span><span class="fl">2</span><span class="op">)</span><span class="op">/</span><span class="va">E</span><span class="op">)</span>
<span class="co">#&gt; [1] 0.32</span>

<span class="co"># compute chi-square</span>
<span class="fu"><a href="https://rdrr.io/r/stats/chisq.test.html">chisq.test</a></span><span class="op">(</span>x<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">23</span>,<span class="fl">27</span><span class="op">)</span><span class="op">)</span>
<span class="co">#&gt; </span>
<span class="co">#&gt;  Chi-squared test for given probabilities</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; data:  c(23, 27)</span>
<span class="co">#&gt; X-squared = 0.32, df = 1, p-value = 0.5716</span></code></pre></div>
<p>The above shows two ways to compute <span class="math inline">\(\chi^2\)</span> for this example, including using the base R function <span class="math inline">\(chisq.test()\)</span>. The obtained value of .32 in our case is fairly small because the differences between the obtained and expected frequencies were fairly small. If the differences were larger, then the <span class="math inline">\(\chi^2\)</span> sample statistic would be much larger, e.g:</p>
<div class="sourceCode" id="cb327"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/stats/chisq.test.html">chisq.test</a></span><span class="op">(</span>x<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">47</span>,<span class="fl">3</span><span class="op">)</span><span class="op">)</span>
<span class="co">#&gt; </span>
<span class="co">#&gt;  Chi-squared test for given probabilities</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; data:  c(47, 3)</span>
<span class="co">#&gt; X-squared = 38.72, df = 1, p-value = 4.892e-10</span></code></pre></div>
<p>Both times the base R function returned the <span class="math inline">\(\chi^2\)</span> sample statistic (computed from the data and assumed theoretical frequencies). The function also return information about degrees of freedom (df), and a p-value. These additional values refer to information from a <span class="math inline">\(\chi^2\)</span> distribution. Under appropriate conditions, the <span class="math inline">\(\chi^2\)</span> sample statistic can be compared to a <span class="math inline">\(\chi^2\)</span> distribution for the purposes of statistical inference.</p>
</div>
<div id="the-chi2-distribution" class="section level3" number="9.5.2">
<h3>
<span class="header-section-number">9.5.2</span> The <span class="math inline">\(\chi^2\)</span> distribution<a class="anchor" aria-label="anchor" href="#the-chi2-distribution"><i class="fas fa-link"></i></a>
</h3>
<p>The shape of <span class="math inline">\(\chi^2\)</span> distribution depends on a parameter called <span class="math inline">\(k\)</span>. When, <span class="math inline">\(k = 1\)</span>, the <span class="math inline">\(\chi^2\)</span> distribution is defined as the unit normal distribution squared.</p>
<div class="sourceCode" id="cb328"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># normal histogram</span>
<span class="fu"><a href="https://rdrr.io/r/graphics/hist.html">hist</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="fl">10000</span>,<span class="fl">0</span>,<span class="fl">1</span><span class="op">)</span>, breaks <span class="op">=</span> <span class="fl">100</span><span class="op">)</span></code></pre></div>
<div class="inline-figure"><img src="Lab9_Chisquare_files/figure-html/unnamed-chunk-10-1.png" width="100%"></div>
<div class="sourceCode" id="cb329"><pre class="downlit sourceCode r">
<code class="sourceCode R">
<span class="co"># chi-squared with k = 1</span>
<span class="fu"><a href="https://rdrr.io/r/graphics/hist.html">hist</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="fl">10000</span>,<span class="fl">0</span>,<span class="fl">1</span><span class="op">)</span><span class="op">^</span><span class="fl">2</span>, breaks <span class="op">=</span> <span class="fl">100</span><span class="op">)</span></code></pre></div>
<div class="inline-figure"><img src="Lab9_Chisquare_files/figure-html/unnamed-chunk-10-2.png" width="100%"></div>
<p>R has distribution functions for <span class="math inline">\(\chi^2\)</span>, including <code><a href="https://rdrr.io/r/stats/Chisquare.html">dchisq()</a></code>, <code><a href="https://rdrr.io/r/stats/Chisquare.html">pchisq()</a></code>, <code><a href="https://rdrr.io/r/stats/Chisquare.html">qchisq()</a></code>, <code><a href="https://rdrr.io/r/stats/Chisquare.html">rchisq()</a></code>. So, if we sampled random deviates using <code><a href="https://rdrr.io/r/stats/Chisquare.html">rchisq()</a></code>, with k = 1 (equivalent to df = 1), we should get the same histogram as above:</p>
<div class="sourceCode" id="cb330"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/graphics/hist.html">hist</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Chisquare.html">rchisq</a></span><span class="op">(</span><span class="fl">10000</span>,<span class="fl">1</span><span class="op">)</span>, breaks<span class="op">=</span><span class="fl">100</span><span class="op">)</span></code></pre></div>
<div class="inline-figure"><img src="Lab9_Chisquare_files/figure-html/unnamed-chunk-11-1.png" width="100%"></div>
<p>So, at its simplest, <span class="math inline">\(\chi^2\)</span> is just the normal distribution squared.</p>
<p>When <span class="math inline">\(k &gt; 1\)</span>, the <span class="math inline">\(\chi^2\)</span> distribution is defined as:</p>
<p><span class="math inline">\(\chi^2 = \sum_{i=1}^k Z_i^2\)</span></p>
<p>Where, <span class="math inline">\(Z_i\)</span> are independent samples from a unit normal distribution. In other words, <span class="math inline">\(\chi^2\)</span> is the distribution of the <strong>sum of squared values</strong> from a unit normal distribution, and <span class="math inline">\(k\)</span> is the number of independent samples in each squared sum.</p>
<p>To clarify, let’s use R:</p>
<div class="sourceCode" id="cb331"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># k = 1</span>
<span class="va">from_normal</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/lapply.html">replicate</a></span><span class="op">(</span><span class="fl">10000</span>, <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="fl">1</span>,<span class="fl">0</span>,<span class="fl">1</span><span class="op">)</span><span class="op">^</span><span class="fl">2</span><span class="op">)</span>
<span class="va">from_chisq</span>  <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Chisquare.html">rchisq</a></span><span class="op">(</span><span class="fl">10000</span>,<span class="fl">1</span><span class="op">)</span>
<span class="va">plot_df</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span>values <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="va">from_normal</span>,
                                 <span class="va">from_chisq</span><span class="op">)</span>,
                      source <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"normal^2"</span>,<span class="st">"chisq"</span><span class="op">)</span><span class="op">)</span>

<span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="http://ggplot2.tidyverse.org">ggplot2</a></span><span class="op">)</span>
<span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="va">plot_df</span>, <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x<span class="op">=</span><span class="va">values</span><span class="op">)</span><span class="op">)</span><span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_histogram.html">geom_histogram</a></span><span class="op">(</span>bins<span class="op">=</span><span class="fl">100</span><span class="op">)</span><span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">ggtitle</a></span><span class="op">(</span><span class="st">"k=1"</span><span class="op">)</span><span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/facet_wrap.html">facet_wrap</a></span><span class="op">(</span><span class="op">~</span><span class="va">source</span><span class="op">)</span></code></pre></div>
<div class="inline-figure"><img src="Lab9_Chisquare_files/figure-html/unnamed-chunk-12-1.png" width="100%"></div>
<div class="sourceCode" id="cb332"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># k = 2</span>
<span class="va">from_normal</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/lapply.html">replicate</a></span><span class="op">(</span><span class="fl">10000</span>, <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="fl">2</span>,<span class="fl">0</span>,<span class="fl">1</span><span class="op">)</span><span class="op">^</span><span class="fl">2</span><span class="op">)</span><span class="op">)</span>
<span class="va">from_chisq</span>  <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Chisquare.html">rchisq</a></span><span class="op">(</span><span class="fl">10000</span>,<span class="fl">2</span><span class="op">)</span>
<span class="va">plot_df</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span>values <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="va">from_normal</span>,
                                 <span class="va">from_chisq</span><span class="op">)</span>,
                      source <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"normal^2"</span>,<span class="st">"chisq"</span><span class="op">)</span><span class="op">)</span>

<span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="http://ggplot2.tidyverse.org">ggplot2</a></span><span class="op">)</span>
<span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="va">plot_df</span>, <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x<span class="op">=</span><span class="va">values</span><span class="op">)</span><span class="op">)</span><span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_histogram.html">geom_histogram</a></span><span class="op">(</span>bins<span class="op">=</span><span class="fl">100</span><span class="op">)</span><span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">ggtitle</a></span><span class="op">(</span><span class="st">"k=2"</span><span class="op">)</span><span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/facet_wrap.html">facet_wrap</a></span><span class="op">(</span><span class="op">~</span><span class="va">source</span><span class="op">)</span></code></pre></div>
<div class="inline-figure"><img src="Lab9_Chisquare_files/figure-html/unnamed-chunk-13-1.png" width="100%"></div>
<div class="sourceCode" id="cb333"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># k = 3</span>
<span class="va">from_normal</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/lapply.html">replicate</a></span><span class="op">(</span><span class="fl">10000</span>, <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="fl">3</span>,<span class="fl">0</span>,<span class="fl">1</span><span class="op">)</span><span class="op">^</span><span class="fl">2</span><span class="op">)</span><span class="op">)</span>
<span class="va">from_chisq</span>  <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Chisquare.html">rchisq</a></span><span class="op">(</span><span class="fl">10000</span>,<span class="fl">3</span><span class="op">)</span>
<span class="va">plot_df</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span>values <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="va">from_normal</span>,
                                 <span class="va">from_chisq</span><span class="op">)</span>,
                      source <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"normal^2"</span>,<span class="st">"chisq"</span><span class="op">)</span><span class="op">)</span>

<span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="http://ggplot2.tidyverse.org">ggplot2</a></span><span class="op">)</span>
<span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="va">plot_df</span>, <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x<span class="op">=</span><span class="va">values</span><span class="op">)</span><span class="op">)</span><span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_histogram.html">geom_histogram</a></span><span class="op">(</span>bins<span class="op">=</span><span class="fl">100</span><span class="op">)</span><span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">ggtitle</a></span><span class="op">(</span><span class="st">"k=3"</span><span class="op">)</span><span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/facet_wrap.html">facet_wrap</a></span><span class="op">(</span><span class="op">~</span><span class="va">source</span><span class="op">)</span></code></pre></div>
<div class="inline-figure"><img src="Lab9_Chisquare_files/figure-html/unnamed-chunk-14-1.png" width="100%"></div>
<div class="sourceCode" id="cb334"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># k = 5</span>
<span class="va">from_normal</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/lapply.html">replicate</a></span><span class="op">(</span><span class="fl">10000</span>, <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="fl">5</span>,<span class="fl">0</span>,<span class="fl">1</span><span class="op">)</span><span class="op">^</span><span class="fl">2</span><span class="op">)</span><span class="op">)</span>
<span class="va">from_chisq</span>  <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Chisquare.html">rchisq</a></span><span class="op">(</span><span class="fl">10000</span>,<span class="fl">5</span><span class="op">)</span>
<span class="va">plot_df</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span>values <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="va">from_normal</span>,
                                 <span class="va">from_chisq</span><span class="op">)</span>,
                      source <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"normal^2"</span>,<span class="st">"chisq"</span><span class="op">)</span><span class="op">)</span>

<span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="http://ggplot2.tidyverse.org">ggplot2</a></span><span class="op">)</span>
<span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="va">plot_df</span>, <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x<span class="op">=</span><span class="va">values</span><span class="op">)</span><span class="op">)</span><span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_histogram.html">geom_histogram</a></span><span class="op">(</span>bins<span class="op">=</span><span class="fl">100</span><span class="op">)</span><span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">ggtitle</a></span><span class="op">(</span><span class="st">"k=5"</span><span class="op">)</span><span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/facet_wrap.html">facet_wrap</a></span><span class="op">(</span><span class="op">~</span><span class="va">source</span><span class="op">)</span></code></pre></div>
<div class="inline-figure"><img src="Lab9_Chisquare_files/figure-html/unnamed-chunk-15-1.png" width="100%"></div>
<p>We can get a glimpse of what the <span class="math inline">\(\chi^2\)</span> distribution looks like across a range of <span class="math inline">\(k\)</span> by plotting the pdf (probability density function), using <code><a href="https://rdrr.io/r/stats/Chisquare.html">dchisq()</a></code>.</p>
<div class="sourceCode" id="cb335"><pre class="downlit sourceCode r">
<code class="sourceCode R">
<span class="va">plot_df</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span>values <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Chisquare.html">dchisq</a></span><span class="op">(</span>x<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span><span class="fl">0</span>,<span class="fl">20</span>,length.out <span class="op">=</span> <span class="fl">100</span><span class="op">)</span>, df<span class="op">=</span><span class="fl">1</span><span class="op">)</span>,
                                 <span class="fu"><a href="https://rdrr.io/r/stats/Chisquare.html">dchisq</a></span><span class="op">(</span>x<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span><span class="fl">0</span>,<span class="fl">20</span>,length.out <span class="op">=</span> <span class="fl">100</span><span class="op">)</span>, df<span class="op">=</span><span class="fl">3</span><span class="op">)</span>,
                                 <span class="fu"><a href="https://rdrr.io/r/stats/Chisquare.html">dchisq</a></span><span class="op">(</span>x<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span><span class="fl">0</span>,<span class="fl">20</span>,length.out <span class="op">=</span> <span class="fl">100</span><span class="op">)</span>, df<span class="op">=</span><span class="fl">5</span><span class="op">)</span>,
                                 <span class="fu"><a href="https://rdrr.io/r/stats/Chisquare.html">dchisq</a></span><span class="op">(</span>x<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span><span class="fl">0</span>,<span class="fl">20</span>,length.out <span class="op">=</span> <span class="fl">100</span><span class="op">)</span>, df<span class="op">=</span><span class="fl">9</span><span class="op">)</span>,
                                 <span class="fu"><a href="https://rdrr.io/r/stats/Chisquare.html">dchisq</a></span><span class="op">(</span>x<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span><span class="fl">0</span>,<span class="fl">20</span>,length.out <span class="op">=</span> <span class="fl">100</span><span class="op">)</span>, df<span class="op">=</span><span class="fl">11</span><span class="op">)</span>
                                 <span class="op">)</span>,
                      x <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span><span class="fl">0</span>,<span class="fl">20</span>,length.out <span class="op">=</span> <span class="fl">100</span><span class="op">)</span>,<span class="fl">5</span><span class="op">)</span>,
                      k <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/factor.html">as.factor</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">1</span>,<span class="fl">3</span>,<span class="fl">5</span>,<span class="fl">9</span>,<span class="fl">11</span><span class="op">)</span>, each <span class="op">=</span> <span class="fl">100</span><span class="op">)</span><span class="op">)</span>
                      <span class="op">)</span>

<span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="va">plot_df</span>, <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">x</span>, y<span class="op">=</span><span class="va">values</span>, color<span class="op">=</span><span class="va">k</span>, group<span class="op">=</span><span class="va">k</span><span class="op">)</span><span class="op">)</span><span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_path.html">geom_line</a></span><span class="op">(</span><span class="op">)</span><span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">ylab</a></span><span class="op">(</span><span class="st">"density"</span><span class="op">)</span><span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">xlab</a></span><span class="op">(</span><span class="st">"chi-squared"</span><span class="op">)</span><span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/scale_continuous.html">scale_x_continuous</a></span><span class="op">(</span>breaks<span class="op">=</span><span class="fl">0</span><span class="op">:</span><span class="fl">20</span><span class="op">)</span></code></pre></div>
<p><img src="Lab9_Chisquare_files/figure-html/unnamed-chunk-16-1.png" width="100%">
### Developing intuitions about <span class="math inline">\(\chi^2\)</span></p>
<ol style="list-style-type: decimal">
<li>Let’s say you randomly sampled 5 numbers from a unit normal distribution (mean = 0 and sd =1), and then you squared those numbers, and then added them all up. What would you expect this number to be?</li>
</ol>
<div class="sourceCode" id="cb336"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">a</span><span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/lapply.html">replicate</a></span><span class="op">(</span><span class="fl">10000</span>,<span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="fl">5</span>,<span class="fl">0</span>,<span class="fl">1</span><span class="op">)</span><span class="op">^</span><span class="fl">2</span><span class="op">)</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/graphics/hist.html">hist</a></span><span class="op">(</span><span class="va">a</span><span class="op">)</span></code></pre></div>
<div class="inline-figure"><img src="Lab9_Chisquare_files/figure-html/unnamed-chunk-17-1.png" width="100%"></div>
<p>The answer is that this number will be distributed as a <span class="math inline">\(\chi^2\)</span> with <span class="math inline">\(k=5\)</span>, referring to the situation of summing the squares of 5 samples from a unit normal distribution.</p>
<ol start="2" style="list-style-type: decimal">
<li>Why does the <span class="math inline">\(\chi^2\)</span> distribution change shape as <span class="math inline">\(k\)</span> increases? If <span class="math inline">\(k\)</span> was a big number like 60, what kind of shape could I expect? If I know <span class="math inline">\(k\)</span>, what should I expect the mean of the <span class="math inline">\(\chi^2\)</span> distribution to be? Answering these questions requires building intuition about <span class="math inline">\(\chi^2\)</span>.</li>
</ol>
<p>In the following, I will take random samples from a unit normal distribution:</p>
<p>What is the expected mean of a unit normal distribution?</p>
<div class="sourceCode" id="cb337"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="fl">10000</span>,<span class="fl">0</span>,<span class="fl">1</span><span class="op">)</span><span class="op">)</span>
<span class="co">#&gt; [1] -0.003677052</span></code></pre></div>
<p>If we square all of the values that we sample from a unit normal distribution (equivalent to <span class="math inline">\(\chi^2\)</span> with <span class="math inline">\(k=1\)</span>), then what would the mean of those squared values be?</p>
<div class="sourceCode" id="cb338"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="fl">10000</span>,<span class="fl">0</span>,<span class="fl">1</span><span class="op">)</span><span class="op">^</span><span class="fl">2</span><span class="op">)</span>
<span class="co">#&gt; [1] 1.007915</span></code></pre></div>
<p>It turns out the answer is 1. There will be no negative values because we are squaring everything. About 68% of the values in a unit normal are between -1 and 1, so squaring all of those will make values between 0 and 1, the rest of the values get increasingly bigger than 1. They all balance out at 1, which is the mean of a squared normal distribution. In other words, the mean of a <span class="math inline">\(\chi^2\)</span> is the same as the <span class="math inline">\(k\)</span> parameter, also called degrees of freedom.</p>
<p>For example, the mean of 10,000 numbers drawn from a <span class="math inline">\(\chi^2\)</span> with k = 10, is:</p>
<div class="sourceCode" id="cb339"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Chisquare.html">rchisq</a></span><span class="op">(</span><span class="fl">10000</span>,<span class="fl">10</span><span class="op">)</span><span class="op">)</span>
<span class="co">#&gt; [1] 9.991172</span></code></pre></div>
<p>Another way to think about this is to recognize that the expected value (mean) from a squared unit normal distribution is 1. So, if you take 10 values from that distribution (i.e., when k = 10), then you are planning to sum up the 10 values that you get, and the expected value for each is 1…summing up 10 ones, gives you 10. The same expectations can be applied to <span class="math inline">\(\chi^2\)</span> distributions of any <span class="math inline">\(k\)</span>.</p>
</div>
</div>
<div id="conceptual-ii-examining-the-approximation" class="section level2" number="9.6">
<h2>
<span class="header-section-number">9.6</span> Conceptual II: Examining the approximation<a class="anchor" aria-label="anchor" href="#conceptual-ii-examining-the-approximation"><i class="fas fa-link"></i></a>
</h2>
<p>In lecture we discussed that the binomial distribution converges on the normal distribution in the long run. This is one of the properties that allows the <span class="math inline">\(\chi^2\)</span> distribution to approximate properties of the binomial distribution.</p>
<p>First, we can visually see that a binomial distribution becomes normally distributed in the long run by simulation. Each simulation involves 10,000 sets of coin flips. The first histogram involves a set of 10 coin flips, and displays the frequency of each possible outcome (# of heads)s. The second histogram shows sets of 100 coin flips. Here, the range of possible outcomes increases, and they appear to be distributed more normally. <strong>As the number of flips in the set increases, the distribution of possible outcomes approaches a normal distribution</strong>.</p>
<div class="sourceCode" id="cb340"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># flip a coin 10 times</span>
<span class="fu"><a href="https://rdrr.io/r/graphics/hist.html">hist</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html">rbinom</a></span><span class="op">(</span><span class="fl">10000</span>,<span class="fl">10</span>,<span class="fl">.5</span><span class="op">)</span>, breaks<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span><span class="fl">0</span>,<span class="fl">10</span>,<span class="fl">1</span><span class="op">)</span><span class="op">)</span></code></pre></div>
<div class="inline-figure"><img src="Lab9_Chisquare_files/figure-html/unnamed-chunk-21-1.png" width="100%"></div>
<div class="sourceCode" id="cb341"><pre class="downlit sourceCode r">
<code class="sourceCode R">
<span class="co"># flip a coin 100 times</span>
<span class="fu"><a href="https://rdrr.io/r/graphics/hist.html">hist</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html">rbinom</a></span><span class="op">(</span><span class="fl">10000</span>,<span class="fl">100</span>,<span class="fl">.5</span><span class="op">)</span>, breaks<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span><span class="fl">20</span>,<span class="fl">80</span>,<span class="fl">1</span><span class="op">)</span><span class="op">)</span></code></pre></div>
<p><img src="Lab9_Chisquare_files/figure-html/unnamed-chunk-21-2.png" width="100%">
Second, let’s develop a sense of the idea that the <span class="math inline">\(\chi^2\)</span> test is approximation of the binomial test.</p>
<p>Consider another coin flipping scenario. Let’s say a coin is flipped 10 times, and there are 2 heads. What is the p-value for a two-tailed test, specifically the probabiltiy of getting 2 or less heads, or 8 or more heads.?</p>
<p>We could use the binomial test, and compute the exact probability.</p>
<div class="sourceCode" id="cb342"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html">pbinom</a></span><span class="op">(</span><span class="fl">2</span>,<span class="fl">10</span>,<span class="fl">.5</span>, lower.tail <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span><span class="op">*</span><span class="fl">2</span>
<span class="co">#&gt; [1] 0.109375</span></code></pre></div>
<p>We could also use a <span class="math inline">\(\chi^2\)</span> test as an approximation:</p>
<div class="sourceCode" id="cb343"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/stats/chisq.test.html">chisq.test</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">2</span>,<span class="fl">8</span><span class="op">)</span><span class="op">)</span>
<span class="co">#&gt; </span>
<span class="co">#&gt;  Chi-squared test for given probabilities</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; data:  c(2, 8)</span>
<span class="co">#&gt; X-squared = 3.6, df = 1, p-value = 0.05778</span></code></pre></div>
<p>In this case there wouldn’t be a good reason to use the <span class="math inline">\(\chi^2\)</span> test, because the binomial test provides an exact probability. Also, because the expected frequencies are very small here, the p-value <span class="math inline">\(\chi^2\)</span> test is about half as small as it should be.</p>
<p>However, if we consider sets of coin flips that are much larger than 10, we increase the expected frequencies (which allows closer convergence to a normal distribution), and the <span class="math inline">\(\chi^2\)</span> and binomial tests both return p-values that are increasingly similar.</p>
<div class="sourceCode" id="cb344"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html">pbinom</a></span><span class="op">(</span><span class="fl">40</span>,<span class="fl">100</span>,<span class="fl">.5</span>, lower.tail <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span><span class="op">*</span><span class="fl">2</span>
<span class="co">#&gt; [1] 0.05688793</span>
<span class="fu"><a href="https://rdrr.io/r/stats/chisq.test.html">chisq.test</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">40</span>,<span class="fl">60</span><span class="op">)</span><span class="op">)</span>
<span class="co">#&gt; </span>
<span class="co">#&gt;  Chi-squared test for given probabilities</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; data:  c(40, 60)</span>
<span class="co">#&gt; X-squared = 4, df = 1, p-value = 0.0455</span></code></pre></div>
<div class="sourceCode" id="cb345"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html">pbinom</a></span><span class="op">(</span><span class="fl">450</span>,<span class="fl">1000</span>,<span class="fl">.5</span>, lower.tail <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span><span class="op">*</span><span class="fl">2</span>
<span class="co">#&gt; [1] 0.001730536</span>
<span class="fu"><a href="https://rdrr.io/r/stats/chisq.test.html">chisq.test</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">450</span>,<span class="fl">550</span><span class="op">)</span><span class="op">)</span>
<span class="co">#&gt; </span>
<span class="co">#&gt;  Chi-squared test for given probabilities</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; data:  c(450, 550)</span>
<span class="co">#&gt; X-squared = 10, df = 1, p-value = 0.001565</span></code></pre></div>
<div class="sourceCode" id="cb346"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html">pbinom</a></span><span class="op">(</span><span class="fl">4900</span>,<span class="fl">10000</span>,<span class="fl">.5</span>, lower.tail <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span><span class="op">*</span><span class="fl">2</span>
<span class="co">#&gt; [1] 0.04658553</span>
<span class="fu"><a href="https://rdrr.io/r/stats/chisq.test.html">chisq.test</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">4900</span>,<span class="fl">5100</span><span class="op">)</span><span class="op">)</span>
<span class="co">#&gt; </span>
<span class="co">#&gt;  Chi-squared test for given probabilities</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; data:  c(4900, 5100)</span>
<span class="co">#&gt; X-squared = 4, df = 1, p-value = 0.0455</span></code></pre></div>
</div>
<div id="lab-9-generalization-assignment" class="section level2" number="9.7">
<h2>
<span class="header-section-number">9.7</span> Lab 9 Generalization Assignment<a class="anchor" aria-label="anchor" href="#lab-9-generalization-assignment"><i class="fas fa-link"></i></a>
</h2>
<div class="videoWrapper">
<iframe width="560" height="315" src="https://www.youtube.com/embed/n4RchGANJWg" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
</div>
<div id="instructions-8" class="section level3" number="9.7.1">
<h3>
<span class="header-section-number">9.7.1</span> Instructions<a class="anchor" aria-label="anchor" href="#instructions-8"><i class="fas fa-link"></i></a>
</h3>
<p>In general, labs will present a discussion of problems and issues with example code like above, and then students will be tasked with completing generalization assignments, showing that they can work with the concepts and tools independently.</p>
<p>Your assignment instructions are the following:</p>
<ol style="list-style-type: decimal">
<li>Work inside the R project “StatsLab1” you have been using</li>
<li>Create a new R Markdown document called “Lab9.Rmd”</li>
<li>Use Lab9.Rmd to show your work attempting to solve the following generalization problems. Commit your work regularly so that it appears on your Github repository.</li>
<li>
<strong>For each problem, make a note about how much of the problem you believe you can solve independently without help</strong>. For example, if you needed to watch the help video and are unable to solve the problem on your own without copying the answers, then your note would be 0. If you are confident you can complete the problem from scratch completely on your own, your note would be 100. It is OK to have all 0s or 100s anything in between.</li>
<li>Submit your github repository link for Lab 9 on blackboard.</li>
</ol>
</div>
<div id="problems-8" class="section level3" number="9.7.2">
<h3>
<span class="header-section-number">9.7.2</span> Problems<a class="anchor" aria-label="anchor" href="#problems-8"><i class="fas fa-link"></i></a>
</h3>
<ol style="list-style-type: decimal">
<li>The following paper links to open data, and describes a design where two chi-square tests are performed for Experiment 1 (A copy of this paper will be made available).</li>
</ol>
<p>Silver, A. M., Stahl, A. E., Loiotile, R., Smith-Flores, A. S., &amp; Feigenson, L. (2020). When Not Choosing Leads to Not Liking: Choice-Induced Preference in Infancy. Psychological Science, 0956797620954491.</p>
<p>Obtain the data from the online repository, show your code for loading it into R, then conduct the same tests reported in Experiment 1 that the authors conducted. These include one binomial test, and two chi-square tests. Briefly report your re-analysis, and discuss whether you obtained the same values as the authors did (6 points).</p>
<p><strong>Important Note:</strong> In my own re-analysis I was able to obtain all of the same values that the authors provided in their results section. However, in my view the authors also misused the chi-square test, especially for the test of independence involving age. So, it is ok if you are unable to reproduce that analysis. However, it is instructive to try and reproduce what the authors did to form an opinion about whether the test was applied in a sound manner.</p>
<p><strong>Solution script</strong>: I am also providing the .rmd for lab 9 that I wrote in the solution video here <a href="https://github.com/CrumpLab/psyc7709Lab/blob/master/lab_solutions/Lab9.Rmd" class="uri">https://github.com/CrumpLab/psyc7709Lab/blob/master/lab_solutions/Lab9.Rmd</a>.</p>
<p><strong>Update on misuse of chi-square test in the above paper</strong>. As we discussed in class and in the solution video, it appears we accidentally found an example in the recent literature where a chi-square test was used incorrectly. In the solution video I didn’t provide a clear reason to demonstrate why the chi-square test was misused. So, I thought I would write an addendum to this lab.</p>
<p>To recap, the authors measured a choice made by 21 infants. The age of each infant was measured in months (to two decimal places). They reported a chi-square test of independence to determine whether age was independent of the choice. For example, they reported: <span class="math inline">\(\chi^2\)</span> (19,N=21) =18.24,p=.506. These values are in some sense correct. For example:</p>
<div class="sourceCode" id="cb347"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/stats/Chisquare.html">pchisq</a></span><span class="op">(</span><span class="fl">18.24</span>, <span class="fl">19</span>, lower.tail <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span>
<span class="co">#&gt; [1] 0.5064639</span></code></pre></div>
<p>However, it appears that the authors treated the infant’s ages, measured a continuous variable, as a categorical variable. And, as it happened, there were two infants who happened to be exactly 11.66 months old. As a result, there were 21 infants, and 20 different age categories. If a contingency table is constructed to represent 20 age categories, and 2 choice options, you get a 20x2 table. This table has (20-1)(2-1) = 19 degrees of freedom. In my solution video I showed an example of how the authors might have constructed that table from their data, and I was able to obtain the same chi-square value that they reported, suggesting that they did construct such a table.</p>
<p>There are several problems here. One of the problems that I will focus on is the conversion of a continuous age variable into a categorical variable. I was expecting the authors to bin ages, say into two categories: younger vs. older. Instead, they used each infant’s age as a category level. It happened to be the case that two infants had exactly the same age (11.66 months), but if that hadn’t happened, the table would have had 21 levels for age (because there were 21 infants).</p>
<p>Consider what occurs if you treat each subject as a unique level in a contingency table, especially in an experiment that involves the subject making a single choice between two alternatives. We will see that the answer is, you always get the same chi-square value. No matter what the subjects do.</p>
<p>Here is an example contingency table with 5 subjects. In this case, each column represents a subject. Row 1 represents choice A, and row 2 choice 2. Each subject makes a choice, and their choice is counted in the appropriate row.</p>
<div class="sourceCode" id="cb348"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/base/lapply.html">replicate</a></span><span class="op">(</span><span class="fl">5</span>,<span class="fu"><a href="https://rdrr.io/r/base/sample.html">sample</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">1</span>,<span class="fl">0</span><span class="op">)</span>,<span class="fl">2</span><span class="op">)</span><span class="op">)</span>
<span class="co">#&gt;      [,1] [,2] [,3] [,4] [,5]</span>
<span class="co">#&gt; [1,]    1    1    0    1    0</span>
<span class="co">#&gt; [2,]    0    0    1    0    1</span></code></pre></div>
<p>This is a contingency table, so it is possible to compute a chi-square test on this table.</p>
<div class="sourceCode" id="cb349"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/stats/chisq.test.html">chisq.test</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/lapply.html">replicate</a></span><span class="op">(</span><span class="fl">5</span>,<span class="fu"><a href="https://rdrr.io/r/base/sample.html">sample</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">1</span>,<span class="fl">0</span><span class="op">)</span>,<span class="fl">2</span><span class="op">)</span><span class="op">)</span><span class="op">)</span>
<span class="co">#&gt; </span>
<span class="co">#&gt;  Pearson's Chi-squared test</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; data:  replicate(5, sample(c(1, 0), 2))</span>
<span class="co">#&gt; X-squared = 5, df = 4, p-value = 0.2873</span></code></pre></div>
<p>However, look at what happens. We obtain a chi-squared value of 5. And, this is what will always happen, no matter what choices each subject makes:</p>
<p>Every time this function runs, the choices made by each simulated subject are randomized. However, no matter what happens, the chi-square value is always five.</p>
<div class="sourceCode" id="cb350"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/stats/chisq.test.html">chisq.test</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/lapply.html">replicate</a></span><span class="op">(</span><span class="fl">5</span>,<span class="fu"><a href="https://rdrr.io/r/base/sample.html">sample</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">1</span>,<span class="fl">0</span><span class="op">)</span>,<span class="fl">2</span><span class="op">)</span><span class="op">)</span><span class="op">)</span>
<span class="co">#&gt; </span>
<span class="co">#&gt;  Pearson's Chi-squared test</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; data:  replicate(5, sample(c(1, 0), 2))</span>
<span class="co">#&gt; X-squared = 5, df = 4, p-value = 0.2873</span></code></pre></div>
<p>This is effectively what the authors did. For example, consider what would happen to the authors data if they excluded the two infants who had the exact same age. That table would have choices from 19 infants.</p>
<p>We can simulate any possible outcome this way:</p>
<div class="sourceCode" id="cb351"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/stats/chisq.test.html">chisq.test</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/lapply.html">replicate</a></span><span class="op">(</span><span class="fl">19</span>,<span class="fu"><a href="https://rdrr.io/r/base/sample.html">sample</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">1</span>,<span class="fl">0</span><span class="op">)</span>,<span class="fl">2</span><span class="op">)</span><span class="op">)</span><span class="op">)</span>
<span class="co">#&gt; </span>
<span class="co">#&gt;  Pearson's Chi-squared test</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; data:  replicate(19, sample(c(1, 0), 2))</span>
<span class="co">#&gt; X-squared = 19, df = 18, p-value = 0.3918</span></code></pre></div>
<p>No matter choices the infants make (either A or B), they will always make one of them, and not the other. And, the observed chi-square value will always be the same as the number of subjects. So, this test does more to confirm the number of the infants used in the experiment than it does to assess the independence of age from the choices.</p>
<p>Finally, if you create a contingency table where each subject has their own category level…and then conduct a chi-square test of independence to see if the subjects are independent from the choices that they made, I would think the major problem there is that the subjects couldn’t be independent of the choices they made, because they were the ones making the choices.</p>
<!-- ## Conceptual III: Testing independence -->
<!-- A common use of $\chi^2$ tests is to examine frequency data and determine whether the obtained frequencies are expected or unexpected, depending on some theoretical expectations for the frequencies. -->
<!-- It is worth looking at a simple example. Karl Pearson's first example from 1900 involved a dice rolling experiment, which is described in Example II. Let's look an even simpler example: -->
<!-- ### Example I -->
<!-- You have a die, you roll it 120 times, and you count how many times each of the possible numbers (1 to 6) are rolled. You assume the die is fair, and that each side should come up 1/6 times, or on average 20 times each. You obtain these counts and compute $\chi^2$. In this case the test statistic computed from the data is $\chi^2 = 9$. -->
<!-- ```{r} -->
<!-- die_rolls <- data.frame(side = 1:6, -->
<!--                         observed = c(27,13,24,16,25,15), -->
<!--                         expected = rep(20,6)) -->
<!-- knitr::kable(die_rolls) -->
<!-- chisq.test(die_rolls$observed) -->
<!-- ``` -->
<!-- You want to make an inference about the data, specifically you want to know whether the data could have been obtained from a fair coin. It is possible to use a $\chi^2$ test for purposes of inference in this case, **but it is important to recognize the alternative options at your disposal, and how they are related or not related to the $\chi^2$ test**. -->
<!-- 1) We have already covered the permutation test in this course. A situation involving rolling a die 120 times and counting the outcomes across six categories (1 to 6), could be expressed as a permutation test. As a result, exact probabilities for every possible outcome can be computed for this situation. We do not need to do a $\chi^2$ test, which would only be an approximation to the exact probabilities. However, it would be practically difficult to do the permutation test, because it would involve 120! factorial possible outcomes. -->
<!-- 2) We have already covered the randomization test in this course. We could sample randomly from the possible permutations and use a monte-carlo simulation to estimate the probabilities of any outcome. -->
<!-- 3) We could use a $\chi^2$ test, but this would involve recognizing that the $\chi^2$ test, under some conditions, provides a pretty approximation to the true null distribution for this situation. -->
<!-- #### A simulation example -->
<!-- Let's do a randomization test for this situation to illustrate the above considerations more clearly: -->
<!-- We can use `sample` and `table` to simulate the process of rolling a die 120 times, and counting how many of each number was rolled. -->
<!-- ```{r} -->
<!-- table(sample(1:6,120, replace=TRUE)) -->
<!-- ``` -->
<!-- We can also compute the observed $\chi^2$ for a new simulated experiment: -->
<!-- ```{r} -->
<!-- chisq.test(table(sample(1:6,120, replace=TRUE)))$statistic -->
<!-- ``` -->
<!-- So, if we wanted to quickly simulate the whole experiment 10000 times, we could generate a sampling distribution of $\chi^2$ values. -->
<!-- ```{r} -->
<!-- sampling_chi <- replicate(10000,chisq.test(table(sample(1:6,120, replace=TRUE)))$statistic) -->
<!-- ``` -->
<!-- Now, we could ask what proportion of times did we get a value of 9 or greater? -->
<!-- ```{r} -->
<!-- length(sampling_chi[sampling_chi > 9])/10000 -->
<!-- ``` -->
<!-- And we get a similar answer as we did using the $\chi^$ test earlier. -->
<!-- There is an important difference to apprehend here. The sampling distribution of $\chi^2$ that we just made is not the same as a $\chi^2$ distribution. -->
<!-- For example, we could repeat our randomization test, but use a different sample statistic to summarize the observed data. If I wanted to summarize the amount error between observed frequencies and expected frequencies, I could just as easily sum up the absolute differences between the two: -->
<!-- ```{r} -->
<!-- die_rolls$observed-die_rolls$expected -->
<!-- abs(die_rolls$observed-die_rolls$expected) -->
<!-- sum(abs(die_rolls$observed-die_rolls$expected)) -->
<!-- ``` -->
<!-- I could use the sum of the absolute difference as the sample statistic, and create sampling distribution for that: -->
<!-- ```{r} -->
<!-- sampling_chi_abs <- replicate(10000,sum(abs(table(sample(1:6,120, replace=TRUE)) - 20))) -->
<!-- ``` -->
<!-- And, then see what the probability is of getting a value larger than 32: -->
<!-- ```{r} -->
<!-- length(sampling_chi_abs[sampling_chi_abs > 32])/10000 -->
<!-- ``` -->
<!-- In this case we get a lower probability. And, I have created a kind of complicated situation for inference because I am now pointing to three different null distributions. First, we have the $\chi^2$ distribution with df = 5 (which we are still in the process of understanding). Second, we have the sampling disrtribution of $\chi^2$ from the randomization test. Third, we have a sampling distribution of the sum of the absolute differences between observed and expected values. In my view, these are all legitimate null distributions that could be used for inference. -->
<!-- ### Limitations -->
<!-- The $\chi^2$ test is an approximation. In many situations the true-null distribution is expected to converge onto the properties of $\chi^2$ distributions, which is why the test can be appropriate for generating probabilities about a null-hypothesis. -->
<!-- However, because the $\chi^2$ test is an approximation, there are situations where the approximation falls apart. This is especially a problem when the theoretical frequencies are small. -->
<!-- For example, let's repeat our die rolling experiment, buy only roll the die 6 times, and each time count how many times we get each number: -->
<!-- ```{r} -->
<!-- die_rolls <- data.frame(side = 1:6, -->
<!--                         observed = c(0,1,0,0,0,5), -->
<!--                         expected = rep(1,6)) -->
<!-- knitr::kable(die_rolls) -->
<!-- chisq.test(die_rolls$observed) -->
<!-- ``` -->
<!-- Notice, R returns a warning that the $\chi^2$ approximation may be incorrect. What is the issue? -->
<!-- First, rolling a die 6 times and counting the occurrence of each number out of 6 involves a discrete number of possible outcomes. There are $6^6 = 46656$ possible outcomes. -->
<!-- ```{r} -->
<!-- possibility_matrix <- matrix(0,nrow=46656,ncol=6) -->
<!-- row_count<-0 -->
<!-- for(p1 in 1:6){ -->
<!--   for(p2 in 1:6){ -->
<!--     for(p3 in 1:6){ -->
<!--       for(p4 in 1:6){ -->
<!--         for(p5 in 1:6){ -->
<!--           for(p6 in 1:6){ -->
<!--             row_count<-row_count+1 -->
<!--             possibility_matrix[row_count,] <- c(p1,p2,p3,p4,p5,p6) -->
<!--           } -->
<!--         } -->
<!--       } -->
<!--     } -->
<!--   } -->
<!-- } -->
<!-- count_each <- function(observation, to_count){ -->
<!--   counts <- c() -->
<!--   for(i in 1:length(to_count)){ -->
<!--     counts[i]<-length(observation[observation==to_count[i]]) -->
<!--   } -->
<!--   return(counts) -->
<!-- } -->
<!-- count_matrix <- matrix(0,nrow=46656,ncol=6) -->
<!-- for(i in 1:46656){ -->
<!--   count_matrix[i,] <- count_each(possibility_matrix[i,], 1:6) -->
<!-- } -->
<!-- chi_squared_possibilities <- rowSums(((count_matrix-1)^2)/1) -->
<!-- hist(chi_squared_possibilities, breaks=100) -->
<!-- table(chi_squared_possibilities) -->
<!-- 180/46656 -->
<!-- 6/46656 -->
<!-- hist(rchisq(46656,5),breaks=100) -->
<!-- pchisq(20,5,lower.tail=FALSE) -->
<!-- ``` -->
<!-- ### Example II -->
<!-- Karl Pearson's first example from 1900 involved a dice rolling experiment, described below: -->
<!-- ```{r,echo=FALSE} -->
<!-- knitr::include_graphics("imgs/pearson_dice.png") -->
<!-- ``` -->
<!-- We will use R to reconstruct this example. First, the experiment involved rolling 12 die at once, then counting how many of them showed a five or a six. This was repeated 26306 times. -->
<!-- Our first task is to determine the **Theoretical Frequency** for the outcome of this experiment. These values are listed by Pearson in the above table. Can we reproduce them? -->
<!-- We assume that the 12 die are fair with odds 2/6 to get a 5 or 6. The expected frequencies can be obtained from a binomial distribution, where it is possible to have 0 to 12 "successes" (rolling a 5 or 6), and each success has 2/6 probability of occurring. -->
<!-- ```{r} -->
<!-- round(dbinom(x = 0:12, -->
<!--              size = 12, -->
<!--              prob = 2/6)*26306, digits=0) -->
<!-- ``` -->
<!-- So, we could make two parts of the above table: -->
<!-- ```{r} -->
<!-- chi_square_table <- data.frame( -->
<!--   Num_dice_5_or_6 = 0:12, -->
<!--   Theoretical_frequency = round(dbinom(x = 0:12, -->
<!--              size = 12, -->
<!--              prob = 2/6)*26306, digits=0) -->
<!-- ) -->
<!-- knitr::kable(chi_square_table) -->
<!-- ``` -->
<!-- Pearson's colleague Professor W. F. R. Weldon apparently took the time out of his day to roll 12 die 26306 times, and each time counted how many 5s and 6s occurred, these values are in the "Observed Frequency" column. We would have to enter them in by hand to our table: -->
<!-- ```{r} -->
<!-- chi_square_table <- data.frame( -->
<!--   Num_dice_5_or_6 = 0:12, -->
<!--   Theoretical_frequency = round(dbinom(x = 0:12, -->
<!--              size = 12, -->
<!--              prob = 2/6)*26306, digits=0), -->
<!--   Observed_frequency = c(185,1149,3265,5475,6114, -->
<!--                          5194,3067,1331,403,105,14,4,0) -->
<!-- ) -->
<!-- knitr::kable(chi_square_table) -->
<!-- ``` -->
<!-- Now, the question is whether the observed frequencies differ from the theoretically expected ones? A first step toward deciding this question is to **compute the deviations between the Theoretical and Expected Frequencies**. -->
<!-- ```{r} -->
<!-- library(dplyr) -->
<!-- chi_square_table <- chi_square_table %>% -->
<!--   mutate(Deviation = Observed_frequency-Theoretical_frequency) -->
<!-- knitr::kable(chi_square_table) -->
<!-- ``` -->
<!-- We notice that **there are deviations**. The observed frequencies are **not exactly the same** as the theoretical frequencies. This deviation from the expectation is also termed **error**. It is the difference between what is expected to occur, and what did occur. -->
<!-- However, a major question is **are the deviations unusual or expected?**. We **expect** that there will **always be some deviations** in this situation because the values of each die are determined by random sampling. The chi-square test provides a method to compare the observed deviations with a sampling distribution of expected deviations due to chance. -->
<!-- The next step is to **summarize** the deviations in some convenient way to produce a descriptive sample statistic. This is done with: -->
<!-- $\chi^2 = \sum{\frac{(\text{Observed} - \text{Expected})^2}{\text{Expected}}}$ -->
<!-- $\chi^2 = \sum{\frac{\text{Deviations}^2}{\text{Expected}}}$ -->
<!-- Here are Pearson's calculations: -->
<!-- ```{r, echo=FALSE} -->
<!-- knitr::include_graphics("imgs/pearson_error.png") -->
<!-- ``` -->
<!-- And, we accomplish the same with: -->
<!-- ```{r} -->
<!-- chi_square_table <- chi_square_table %>% -->
<!--   mutate(e_2 = Deviation^2) %>% -->
<!--   mutate(e_2_m = e_2/Theoretical_frequency) -->
<!-- knitr::kable(chi_square_table) -->
<!-- ``` -->
<!-- Finally, the computed chi-square value ($\chi^2$) is: -->
<!-- ```{r} -->
<!-- sum(chi_square_table$e_2_m, na.rm=TRUE) -->
<!-- ``` -->
<!-- Our value is ever so slightly different from Pearson's (43.87), and these differences appear to be due to rounding differences in the Theoretical frequencies for a couple events.  -->
<!-- ### What is $\chi^2$ telling us? -->
<!-- $\chi^2 = \sum{\frac{(\text{Observed} - \text{Expected})^2}{\text{Expected}}}$ -->
<!-- $\chi^2$ is a sample statistic that conveniently summarizes the difference between a set of observed frequencies and theoretically expected frequencies. For each event frequency, the deviation or difference between observed and expected is computed, and then squared, and then divided by the expected frequency. All of these values are then summed to produce a single number, $\chi^2$. In general, $\chi^2$ will approach 0 as the deviations between observed and expected frequencies become smaller, and $\chi^2$ grows larger as the deviations grow larger. -->
<!-- ### Compared to what? -->
<!-- For this example, our big question is to better understand the obtained $\chi^2 = 43.64$. Is this value big or small, expected or unexpected? To answer these kinds of questions, we need to make a comparison. Pearson compares his obtained value to the "null-distribution". This is the distribution of chi-square values that would be expected by chance alone.  -->
<!-- Pearson developed analytic formulas allowing direct calculation of the probabilities associated obtaining particular values of $\chi^2$ under a null-distribution, for example, calculated the probability of obtaining $\chi^2 = 43.87$ as: -->
<!-- ```{r, echo=FALSE} -->
<!-- knitr::include_graphics("imgs/pearson_p.png") -->
<!-- ``` -->
<!-- ### Simulated $\chi^2$ distributions -->
<!-- As a an alternative to Pearson's method, we can use R to create a sampling distribution of $\chi^2$ for the null hypothesis by simulation. -->
<!-- The first step to do that is to simulate Pearson's dice rolling experiment, which allows us to "pretend" rolling 12 dice 26306 times, and counting up how many times a five or six is rolled out of 12. -->
<!-- ```{r} -->
<!-- table(rbinom(26306,12,2/6)) -->
<!-- ``` -->
<!-- Now we can simulate observed frequencies for this experiment, and compute a chi_squared statistic each time. Each time we see a new $\chi^2$ value, showing what happened by chance alone for each simulated experiment. -->
<!-- ```{r} -->
<!-- Theoretical_frequency <- round(dbinom(x = 0:12, -->
<!--              size = 12, -->
<!--              prob = 2/6)*26306, digits=0) -->
<!-- simulated_observed <- table(rbinom(26306,12,2/6)) -->
<!-- deviations_squared <- (simulated_observed-Theoretical_frequency[1:length(simulated_observed)])^2 -->
<!-- chi_squared <- sum(deviations_squared/Theoretical_frequency[1:length(simulated_observed)]) -->
<!-- ``` -->
<!-- To get a good sense of the kinds of values that $\chi^2$ could take by chance alone, we conduct the above 10,000 times in a monte-carlo simulation, to produce a $\chi^2$ distribution. -->
<!-- ```{r} -->
<!-- Theoretical_frequency <- round(dbinom(x = 0:12, -->
<!--              size = 12, -->
<!--              prob = 2/6)*26306, digits=0) -->
<!-- # run monte-carlo -->
<!-- chi_square_dist <- c() -->
<!-- for(i in 1:10000){ -->
<!--   simulated_observed <- table(rbinom(26306,12,2/6)) -->
<!--   deviations_squared <- (simulated_observed-Theoretical_frequency[1:length(simulated_observed)])^2 -->
<!--   normalized_deviations <- deviations_squared/Theoretical_frequency[1:length(simulated_observed)] -->
<!--   chi_squared <- sum(normalized_deviations[is.infinite(normalized_deviations) == FALSE]) -->
<!--   chi_square_dist[i] <- chi_squared -->
<!-- } -->
<!-- # plot -->
<!-- library(ggplot2) -->
<!-- sim_data <- data.frame(num_sims = 1:10000, -->
<!--                        chi_square = chi_square_dist) -->
<!-- ggplot(sim_data ,aes(x=chi_square))+ -->
<!--   geom_histogram(bins=60, color='orange', fill='black', breaks=0:100) + -->
<!--   geom_vline(xintercept = 43, color='red') -->
<!-- length(chi_square_dist[chi_square_dist > 43])/10000 -->
<!-- ``` -->
<!-- ### General principles -->
<!-- Pearson's chi square test has some convenient mathematical properties that allow for direct calculation of probabilities associated with a null chi-square distribution. We have seen that a monte-carlo simulation process produces similar results.  -->
<!-- More generally, we can accomplish the goals of a chi-square test in multiple ways, as long as we can 1) define a useful sample statistic, and 2) estimate the sampling distribution of that statistic under some set of asssumptions (usually the null). -->
<!-- For example, Pearson defined the sample statistic $\chi^2$ as: -->
<!-- $\chi^2 = \sum{\frac{(\text{Observed} - \text{Expected})^2}{\text{Expected}}}$ -->
<!-- This formula does a good job of distilling the deviations between expected and theoretical frequencies down to a single number. However, consider this formula: -->
<!-- $|\chi|_ = \sum|(Observed-Expected)|$ -->
<!-- The above is a sample statistic I just made up, and I'm calling it absolute chi. It is just the sum of the absolute deviations between observed and expected. And, we could use a monte-carlo simulation process to find the sampling distribution for this statistic under the null as well: -->
<!-- ```{r} -->
<!-- Theoretical_frequency <- round(dbinom(x = 0:12, -->
<!--              size = 12, -->
<!--              prob = 2/6)*26306, digits=0) -->
<!-- # run monte-carlo -->
<!-- chi_abs_dist <- c() -->
<!-- for(i in 1:10000){ -->
<!--   simulated_observed <- table(rbinom(26306,12,2/6)) -->
<!--   chi_abs <- sum(abs(simulated_observed-Theoretical_frequency[1:length(simulated_observed)])) -->
<!--   chi_abs_dist[i] <- chi_abs -->
<!-- } -->
<!-- sim_data <- data.frame(num_sims = 1:10000, -->
<!--                        chi_abs = chi_abs_dist) -->
<!-- ggplot(sim_data ,aes(x=chi_abs))+ -->
<!--   geom_histogram(bins=60, color='orange', fill='black')+ -->
<!--   geom_vline(xintercept = sum(abs(chi_square_table$Deviation)), -->
<!--              color='red') -->
<!-- length(chi_abs_dist[chi_abs_dist > sum(abs(chi_square_table$Deviation))])/10000 -->
<!-- ``` -->
<!-- ### A vector of frequencies -->
<!-- The following compute a chi-squared test on a single vector. Without further specification, the assumption is that each of possibilities have an equal probability of occurring, and the p-value reflects the probability of obtaining a chi-square or larger for the given situation. -->
<!-- This computes a p value from a chi-square distribution with df = 2. -->
<!-- ```{r} -->
<!-- chisq.test(x=c(100,100,130)) -->
<!-- ``` -->
<!-- It is also possible to "simulate" the p-value through a monte-carlo process, much like the ones we have been using. In this case, there is no df (degrees of freedom), because the sampling distribution is estimated by simulation, and not approximated using a chi-square distribution with df = 2. -->
<!-- ```{r} -->
<!-- chisq.test(x=c(100,100,130), simulate.p.value = TRUE, B=10000) -->
<!-- ``` -->
<!-- We could reproduce our simulation as follows. The above example involves a total of 330 events, if they were all equally likely to fall into the categories A, B, C, then the expected frequency for each event is 110, 110, and 110.  -->
<!-- ```{r} -->
<!-- sim_chi_square <- replicate(10000, sum(((table(sample(1:3,330,replace=TRUE))-110)^2)/110)) -->
<!-- length(sim_chi_square[sim_chi_square > 5.4545])/10000 -->
<!-- hist(sim_chi_square) -->
<!-- ``` -->
<!-- ### A contingency table -->
<!-- The `chisq.test()` also accepts matrices, which are common for tests of independence. Consider the example from wikipedia <https://en.wikipedia.org/wiki/Chi-squared_test#Example_chi-squared_test_for_categorical_data>. -->
<!-- ```{r, echo=FALSE} -->
<!-- knitr::include_graphics('imgs/wikipedia_chi.png') -->
<!-- ``` -->
<!-- ```{r} -->
<!-- frequency_matrix <- matrix(c(90,60,104,95, -->
<!--                            30,50,51,20, -->
<!--                            30,40,45,35),ncol=4,nrow=3,byrow=TRUE) -->
<!-- chisq.test(frequency_matrix) -->
<!-- ``` -->
<!-- To illustrate the steps involved, let's first compute the expected frequencies. -->
<!-- ```{r} -->
<!-- # calculate expected frequencies assuming Independence -->
<!-- expected_matrix <- matrix(0,ncol=4,nrow=3) -->
<!-- column_sums <- colSums(frequency_matrix) -->
<!-- row_sums <- rowSums(frequency_matrix) -->
<!-- for(i in 1:dim(frequency_matrix)[1]){ -->
<!--   for(j in 1:dim(frequency_matrix)[2]){ -->
<!--     expected_matrix[i,j] <- column_sums[j] * row_sums[i]/sum(frequency_matrix) -->
<!--   } -->
<!-- } -->
<!-- expected_matrix -->
<!-- # Or use linear algebra -->
<!-- t(colSums(frequency_matrix) %*% t(rowSums(frequency_matrix)/650)) -->
<!-- ``` -->
<!-- Next, we compute $\chi^2$: -->
<!-- ```{r} -->
<!-- sum(((frequency_matrix-expected_matrix)^2)/expected_matrix) -->
<!-- ``` -->
<!-- Now, what is the reference null distribution to compare this value too? Pearson's answer is that the null distribution is well approximated by a chi-square distribution with df = 6. -->
<!-- ```{r} -->
<!-- ?pchisq -->
<!-- pchisq(24.5712,df=6, lower.tail=FALSE) -->
<!-- ``` -->
<!-- Finally consider how we could simulate the sampling the distribution, rather than approximate it with a chi-square distribution. -->
<!-- ```{r} -->
<!-- event_probabilities <- expected_matrix/rowSums(expected_matrix) -->
<!-- simulated_dist <- c() -->
<!-- for(iterations  in 1:10000){ -->
<!--   sim_events <- matrix(0,ncol=4,nrow=3) -->
<!--   for(i in 1:3){ -->
<!--     sim <- table(sample(1:4, -->
<!--                  size=sum(expected_matrix[i,]), -->
<!--                  replace=TRUE, -->
<!--                  prob = event_probabilities[i,])) -->
<!--     sim_events[i,]<-sim -->
<!--   } -->
<!--   sim_chi <- sum(((sim_events-expected_matrix)^2)/expected_matrix) -->
<!--   simulated_dist[iterations] <- sim_chi -->
<!-- } -->
<!-- hist(simulated_dist) -->
<!-- length(simulated_dist[simulated_dist > 24.5712])/10000 -->
<!-- ``` -->
<!-- ```{r} -->
<!-- chi_sq <- rep(0,1000000) -->
<!-- for(i in 1:2){ -->
<!--   a <- rnorm(1000000,0,1)^2 -->
<!--   chi_sq <- chi_sq+a -->
<!-- } -->
<!-- hist(chi_sq) -->
<!-- pchisq(5,2,lower.tail=FALSE) -->
<!-- length(chi_sq[chi_sq > 5])/1000000 -->
<!-- ``` -->

</div>
</div>
</div>

  <div class="chapter-nav">
<div class="prev"><a href="z-tests.html"><span class="header-section-number">8</span> Z tests</a></div>
<div class="next"><a href="t-tests.html"><span class="header-section-number">10</span> T-tests</a></div>
</div></main><div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="On this page"><h2>On this page</h2>
      <ul class="nav navbar-nav">
<li><a class="nav-link" href="#chi-square"><span class="header-section-number">9</span> Chi Square</a></li>
<li><a class="nav-link" href="#reading-4"><span class="header-section-number">9.1</span> Reading</a></li>
<li><a class="nav-link" href="#overview-8"><span class="header-section-number">9.2</span> Overview</a></li>
<li>
<a class="nav-link" href="#background"><span class="header-section-number">9.3</span> Background</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#a-brief-history"><span class="header-section-number">9.3.1</span> A brief history</a></li>
<li><a class="nav-link" href="#chi-square-distributions-have-fundamental-properties-that-make-them-widespread-in-statistics"><span class="header-section-number">9.3.2</span> Chi-square distributions have fundamental properties that make them widespread in statistics</a></li>
<li><a class="nav-link" href="#debate-about-correct-usage"><span class="header-section-number">9.3.3</span> Debate about correct usage</a></li>
<li><a class="nav-link" href="#connection-to-previous-lab-concepts"><span class="header-section-number">9.3.4</span> Connection to previous lab concepts</a></li>
</ul>
</li>
<li>
<a class="nav-link" href="#practical-i-chisq.test-in-r"><span class="header-section-number">9.4</span> Practical I: chisq.test() in R</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#chisq.test"><span class="header-section-number">9.4.1</span> chisq.test()</a></li>
<li><a class="nav-link" href="#independence-test-for-a-contingency-table"><span class="header-section-number">9.4.2</span> Independence test for a contingency table</a></li>
</ul>
</li>
<li>
<a class="nav-link" href="#conceptual-i-chi2-distribution-sample-statistic-and-test"><span class="header-section-number">9.5</span> Conceptual I: \(\chi^2\) distribution, sample statistic, and test</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#the-chi2-sample-statistic"><span class="header-section-number">9.5.1</span> The \(\chi^2\) sample statistic</a></li>
<li><a class="nav-link" href="#the-chi2-distribution"><span class="header-section-number">9.5.2</span> The \(\chi^2\) distribution</a></li>
</ul>
</li>
<li><a class="nav-link" href="#conceptual-ii-examining-the-approximation"><span class="header-section-number">9.6</span> Conceptual II: Examining the approximation</a></li>
<li>
<a class="nav-link" href="#lab-9-generalization-assignment"><span class="header-section-number">9.7</span> Lab 9 Generalization Assignment</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#instructions-8"><span class="header-section-number">9.7.1</span> Instructions</a></li>
<li><a class="nav-link" href="#problems-8"><span class="header-section-number">9.7.2</span> Problems</a></li>
</ul>
</li>
</ul>

      <div class="book-extra">
        <ul class="list-unstyled">
<li><a id="book-source" href="https://github.com/CrumpLab/rstatsforpsych/blob/master/Lab9_Chisquare.Rmd">View source <i class="fab fa-github"></i></a></li>
          <li><a id="book-edit" href="https://github.com/CrumpLab/rstatsforpsych/edit/master/Lab9_Chisquare.Rmd">Edit this page <i class="fab fa-github"></i></a></li>
        </ul>
</div>
    </nav>
</div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong>Reproducible statistics for psychologists with R</strong>: Lab Tutorials" was written by Matthew J. C. Crump. </p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>This book was built by the <a class="text-light" href="https://bookdown.org">bookdown</a> R package.</p>
  </div>

</div></div>
</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>
</html>
